{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pj0620/google-colab-notebooks/blob/main/Minesweeper_rl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from scipy.signal import convolve2d\n",
        "%pip install stable-baselines3[extra]\n",
        "\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "!pip install gymnasium[atari]\n",
        "!pip install gymnasium[accept-rom-license]\n",
        "\n",
        "!apt-get install swig cmake ffmpeg\n",
        "!pip install git+https://github.com/DLR-RM/rl-baselines3-zoo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "LZv1Xe1yddn4",
        "outputId": "3d40c705-e55e-4298-dce9-319f0ca2cd90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.9.3)\n",
            "Collecting shimmy~=1.3.0 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra])\n",
            "  Using cached Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (10.4.0)\n",
            "Collecting autorom~=0.6.1 (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
            "  Using cached AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.32.3)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (6.4.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2024.8.30)\n",
            "Using cached AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Using cached Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: shimmy, autorom\n",
            "  Attempting uninstall: shimmy\n",
            "    Found existing installation: Shimmy 0.2.1\n",
            "    Uninstalling Shimmy-0.2.1:\n",
            "      Successfully uninstalled Shimmy-0.2.1\n",
            "  Attempting uninstall: autorom\n",
            "    Found existing installation: AutoROM 0.4.2\n",
            "    Uninstalling AutoROM-0.4.2:\n",
            "      Successfully uninstalled AutoROM-0.4.2\n",
            "Successfully installed autorom-0.6.1 shimmy-1.3.0\n",
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Collecting shimmy<1.0,>=0.1.0 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari])\n",
            "  Using cached Shimmy-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (0.8.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (6.4.5)\n",
            "Using cached Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: shimmy\n",
            "  Attempting uninstall: shimmy\n",
            "    Found existing installation: Shimmy 1.3.0\n",
            "    Uninstalling Shimmy-1.3.0:\n",
            "      Successfully uninstalled Shimmy-1.3.0\n",
            "Successfully installed shimmy-0.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "shimmy"
                ]
              },
              "id": "24eb511aa01c42948656de4f7db18975"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n",
            "Collecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license])\n",
            "  Using cached AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (4.66.5)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2024.8.30)\n",
            "Using cached AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: autorom\n",
            "  Attempting uninstall: autorom\n",
            "    Found existing installation: AutoROM 0.6.1\n",
            "    Uninstalling AutoROM-0.6.1:\n",
            "      Successfully uninstalled AutoROM-0.6.1\n",
            "Successfully installed autorom-0.4.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 887 kB in 1s (1,054 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 123623 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/DLR-RM/rl-baselines3-zoo\n",
            "  Cloning https://github.com/DLR-RM/rl-baselines3-zoo to /tmp/pip-req-build-xfoqz0xi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/rl-baselines3-zoo /tmp/pip-req-build-xfoqz0xi\n",
            "  Resolved https://github.com/DLR-RM/rl-baselines3-zoo to commit 6409c410d0c613dd6efa4582bf75a9fd9658f5a4\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sb3-contrib<3.0,>=2.4.0a10 (from rl_zoo3==2.4.0a10)\n",
            "  Using cached sb3_contrib-2.4.0a10-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: gymnasium~=0.29.1 in /usr/local/lib/python3.10/dist-packages (from rl_zoo3==2.4.0a10) (0.29.1)\n",
            "Collecting huggingface-sb3<4.0,>=3.0 (from rl_zoo3==2.4.0a10)\n",
            "  Using cached huggingface_sb3-3.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from rl_zoo3==2.4.0a10) (4.66.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from rl_zoo3==2.4.0a10) (13.9.3)\n",
            "Collecting optuna>=3.0 (from rl_zoo3==2.4.0a10)\n",
            "  Using cached optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from rl_zoo3==2.4.0a10) (6.0.2)\n",
            "Collecting pytablewriter~=1.2 (from rl_zoo3==2.4.0a10)\n",
            "  Using cached pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium~=0.29.1->rl_zoo3==2.4.0a10) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium~=0.29.1->rl_zoo3==2.4.0a10) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium~=0.29.1->rl_zoo3==2.4.0a10) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium~=0.29.1->rl_zoo3==2.4.0a10) (0.0.4)\n",
            "Requirement already satisfied: huggingface-hub~=0.8 in /usr/local/lib/python3.10/dist-packages (from huggingface-sb3<4.0,>=3.0->rl_zoo3==2.4.0a10) (0.24.7)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from huggingface-sb3<4.0,>=3.0->rl_zoo3==2.4.0a10) (1.1.3)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.0->rl_zoo3==2.4.0a10)\n",
            "  Using cached alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna>=3.0->rl_zoo3==2.4.0a10)\n",
            "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0->rl_zoo3==2.4.0a10) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0->rl_zoo3==2.4.0a10) (2.0.36)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter~=1.2->rl_zoo3==2.4.0a10) (75.1.0)\n",
            "Collecting DataProperty<2,>=1.0.1 (from pytablewriter~=1.2->rl_zoo3==2.4.0a10)\n",
            "  Using cached DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter~=1.2->rl_zoo3==2.4.0a10)\n",
            "  Using cached mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter~=1.2->rl_zoo3==2.4.0a10)\n",
            "  Using cached pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter~=1.2->rl_zoo3==2.4.0a10)\n",
            "  Using cached tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter~=1.2->rl_zoo3==2.4.0a10)\n",
            "  Using cached tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.4.0a10)\n",
            "  Using cached typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting stable-baselines3<3.0,>=2.4.0a6 (from sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10)\n",
            "  Using cached stable_baselines3-2.4.0a10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->rl_zoo3==2.4.0a10) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->rl_zoo3==2.4.0a10) (2.18.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.0->rl_zoo3==2.4.0a10)\n",
            "  Using cached Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3==2.4.0a10) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3==2.4.0a10) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3==2.4.0a10) (2.32.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->rl_zoo3==2.4.0a10) (0.1.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter~=1.2->rl_zoo3==2.4.0a10) (5.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.0->rl_zoo3==2.4.0a10) (3.1.1)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (2.5.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.4.0a10) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.4.0a10) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.0->typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.4.0a10) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna>=3.0->rl_zoo3==2.4.0a10) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (3.2.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3<3.0,>=2.4.0a6->sb3-contrib<3.0,>=2.4.0a10->rl_zoo3==2.4.0a10) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3==2.4.0a10) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3==2.4.0a10) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3==2.4.0a10) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3<4.0,>=3.0->rl_zoo3==2.4.0a10) (2024.8.30)\n",
            "Using cached huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\n",
            "Using cached optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sb3_contrib-2.4.0a10-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Downloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\n",
            "Downloading stable_baselines3-2.4.0a10-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.5/183.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rl_zoo3\n",
            "  Building wheel for rl_zoo3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rl_zoo3: filename=rl_zoo3-2.4.0a10-py3-none-any.whl size=76997 sha256=d8aabff77d7ad866e162b464197aed18c8e15dca78f449173864f0b11d70c5dd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fwh77mhi/wheels/5f/9b/c0/8af7ab740f894e9d66c7707eb4aa58087c9a71dd262e7e6174\n",
            "Successfully built rl_zoo3\n",
            "Installing collected packages: tcolorpy, pathvalidate, mbstrdecoder, Mako, colorlog, typepy, alembic, stable-baselines3, optuna, huggingface-sb3, sb3-contrib, DataProperty, tabledata, pytablewriter, rl_zoo3\n",
            "  Attempting uninstall: stable-baselines3\n",
            "    Found existing installation: stable_baselines3 2.3.2\n",
            "    Uninstalling stable_baselines3-2.3.2:\n",
            "      Successfully uninstalled stable_baselines3-2.3.2\n",
            "Successfully installed DataProperty-1.0.1 Mako-1.3.6 alembic-1.13.3 colorlog-6.9.0 huggingface-sb3-3.0 mbstrdecoder-1.1.3 optuna-4.0.0 pathvalidate-3.2.1 pytablewriter-1.2.0 rl_zoo3-2.4.0a10 sb3-contrib-2.4.0a10 stable-baselines3-2.4.0a10 tabledata-1.3.3 tcolorpy-0.1.6 typepy-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter configurations\n",
        "Create a file named `dql.yml` with the following contents\n",
        "\n",
        "```\n",
        "Minesweeper-v1:\n",
        "  frame_stack: 1\n",
        "  policy: 'CnnPolicy'\n",
        "  n_timesteps: !!float 1e6\n",
        "  buffer_size: 100000\n",
        "  learning_rate: !!float 1e-4\n",
        "  batch_size: 32\n",
        "  learning_starts: 100000\n",
        "  target_update_interval: 1000\n",
        "  train_freq: 4\n",
        "  gradient_steps: 1\n",
        "  exploration_fraction: 0.1\n",
        "  exploration_final_eps: 0.01\n",
        "  # If True, you need to deactivate handle_timeout_termination\n",
        "  # in the replay_buffer_kwargs\n",
        "  optimize_memory_usage: False\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BjNKEnmJ44KS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom gymnasium env"
      ],
      "metadata": {
        "id": "qnhdrAKdlZdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from gymnasium import spaces\n",
        "from skimage.transform import resize\n",
        "\n",
        "class MinesweeperEnvironment(gym.Env):\n",
        "  # Because of google colab, we cannot implement the GUI ('human' render mode)\n",
        "  metadata = {\"render_modes\": [\"console\"]}\n",
        "\n",
        "  def __init__(self, board_size=14, total_bombs=14, render_mode=\"console\"):\n",
        "    super().__init__()\n",
        "    self.render_mode = render_mode\n",
        "    self.board_size = board_size\n",
        "    self.total_bombs = total_bombs\n",
        "\n",
        "    self.visible = np.zeros((self.board_size, self.board_size), dtype=np.uint8)\n",
        "    self.set_bombs()\n",
        "    self.set_values()\n",
        "\n",
        "    # Define observation space\n",
        "    # self.observation_space = spaces.Dict({\n",
        "    #   \"visible_vals\": spaces.Box(low=0, high=8, shape=(self.board_size, self.board_size), dtype=np.int8),\n",
        "    #   \"visible\": spaces.Box(low=0, high=1, shape=(self.board_size, self.board_size), dtype=np.int8)\n",
        "    # })\n",
        "\n",
        "    # self.observation_space = spaces.Box(\n",
        "    #     low=0, high=8, shape=(2 * self.board_size**2,), dtype=np.int8\n",
        "    # )\n",
        "\n",
        "    self.observation_space = spaces.Box(\n",
        "        low=0, high=255, shape=(84, 84, 3), dtype=np.uint8\n",
        "    )\n",
        "\n",
        "    # Define action space\n",
        "    self.action_space = spaces.Discrete(self.board_size**2)\n",
        "\n",
        "    self.last_action = -1\n",
        "\n",
        "  def set_bombs(self):\n",
        "    random.seed(10)\n",
        "    self.bombs = np.zeros(shape=(self.board_size, self.board_size),  dtype=np.uint8)\n",
        "    placed_bombs = 0\n",
        "    while placed_bombs < self.total_bombs:\n",
        "      i = random.randint(0, self.board_size-1)\n",
        "      j = random.randint(0, self.board_size-1)\n",
        "\n",
        "      if self.bombs[i][j] == 0:\n",
        "        self.bombs[i][j] = 1\n",
        "        placed_bombs += 1\n",
        "\n",
        "  def set_values(self):\n",
        "    KERNAL = np.ones((3, 3))\n",
        "    self.vals = convolve2d(self.bombs, KERNAL, mode='same').astype(np.uint8)\n",
        "\n",
        "  def reset(self, seed=None, options=None):\n",
        "    # Reset the environment to an initial state\n",
        "    self.visible = np.zeros((self.board_size, self.board_size), dtype=np.uint8)\n",
        "    self.set_bombs()\n",
        "    self.set_values()\n",
        "    self.last_action = -1\n",
        "\n",
        "    return self.get_state(), {}\n",
        "\n",
        "  def propogate(self, x: int, y: int):\n",
        "    if self.bombs[x][y] == 1 or self.visible[x][y] == 1:\n",
        "      return\n",
        "\n",
        "    if self.vals[x][y] == 0:\n",
        "      self.visible[x][y] = 1\n",
        "      for x_k in [x - 1, x, x + 1]:\n",
        "        for y_k in [y - 1, y, y + 1]:\n",
        "          if (x_k, y_k) == (x, y):\n",
        "            continue\n",
        "\n",
        "          if x_k < 0 or x_k > self.board_size - 1:\n",
        "            continue\n",
        "\n",
        "          if y_k < 0 or y_k > self.board_size - 1:\n",
        "            continue\n",
        "\n",
        "          self.propogate(x_k, y_k)\n",
        "\n",
        "  def step(self, action):\n",
        "    # Implement the logic for taking a step in the environment\n",
        "    x = action // self.board_size\n",
        "    y = action % self.board_size\n",
        "\n",
        "    start_visible_cells = np.sum(self.visible)\n",
        "    start_teminated = bool((self.board_size**2 - start_visible_cells) == self.total_bombs)\n",
        "    if (self.visible[x][y] == 1) or (action == self.last_action) or (self.bombs[x][y] == 1):\n",
        "      return self.get_state(), -100.0, start_teminated, False, {}\n",
        "\n",
        "    self.last_action = action\n",
        "\n",
        "    if self.vals[x][y] == 0:\n",
        "      self.propogate(x, y)\n",
        "\n",
        "    self.visible[x][y] = 1\n",
        "    end_visible_cells = np.sum(self.visible)\n",
        "    teminated = bool((self.board_size**2 - end_visible_cells) == self.total_bombs)\n",
        "    return self.get_state(), float(end_visible_cells) - float(start_visible_cells), teminated, False, {}\n",
        "\n",
        "  def get_state(self):\n",
        "    # print(f\"self.visible: min={self.visible.min()} max={self.visible.max()}\")\n",
        "    # print(f\"self.visible * self.vals: min={(self.visible * self.vals).min()} max={(self.visible * self.vals).max()}\")\n",
        "    res = (255 / 8) * np.stack((self.visible * self.vals, self.visible, np.zeros((self.board_size, self.board_size))), axis=2)\n",
        "    # print(f\"res: min={res.min()} max={res.max()}\")\n",
        "    return resize(res, (84, 84, 3), anti_aliasing=False).astype(np.uint8)\n",
        "    # return np.hstack((np.ravel(self.visible * self.vals), np.ravel(self.visible)))\n",
        "\n",
        "  def render(self, mode=\"console\"):\n",
        "    if self.render_mode != \"console\":\n",
        "        raise NotImplementedError(\"Render mode not supported.\")\n",
        "\n",
        "    # Print the current visible board state\n",
        "    print(\"Current Board:\")\n",
        "    for i in range(self.board_size):\n",
        "        row = \"\"\n",
        "        for j in range(self.board_size):\n",
        "            if self.visible[i][j] == 1:\n",
        "                # If the cell is visible, show its value (number of adjacent bombs)\n",
        "                if self.bombs[i][j] == 1:\n",
        "                  row += f\"B \"\n",
        "                else:\n",
        "                  row += f\"{self.vals[i][j]} \"\n",
        "            else:\n",
        "                # If the cell is hidden, show an asterisk\n",
        "                row += \"* \"\n",
        "        print(row)\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "\n",
        "env = MinesweeperEnvironment(board_size=10, total_bombs=10)\n",
        "\n",
        "# Testing env\n",
        "check_env(env)\n",
        "for round in range(10):\n",
        "  obs, info = env.reset()\n",
        "  for _ in range(10):\n",
        "      # Random action\n",
        "      action = env.action_space.sample()\n",
        "      obs, reward, terminated, truncated, info = env.step(action)\n",
        "      if terminated:\n",
        "          obs, info = env.reset()\n",
        "      # env.render()\n",
        "  env.reset()"
      ],
      "metadata": {
        "id": "k1b3Xo2biryW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbec6410-cbef-4b68-8ded-21d8bb54305e",
        "collapsed": true
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO, A2C, DQN\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "# Instantiate the env\n",
        "vec_env = make_vec_env(MinesweeperEnvironment, n_envs=1)\n",
        "learning_rate = 0.1e-4       # Adjust learning rate\n",
        "buffer_size = 100000       # Size of the replay buffer\n",
        "learning_starts = 10000    # Number of steps before learning starts\n",
        "batch_size = 32            # Batch size for training\n",
        "train_freq = 4             # Frequency of training (in steps)\n",
        "target_update_interval = 500  # Frequency to update target network\n",
        "exploration_fraction = 0.2 # Fraction of total timesteps for exploration\n",
        "exploration_final_eps = 0.01  # Final epsilon for exploration\n",
        "\n",
        "# Instantiate DQN with custom hyperparameters\n",
        "model = DQN(\n",
        "    \"CnnPolicy\",            # Policy type (can also use \"CnnPolicy\" for image-based input)\n",
        "    vec_env,\n",
        "    learning_rate=learning_rate,\n",
        "    buffer_size=buffer_size,\n",
        "    learning_starts=learning_starts,\n",
        "    batch_size=batch_size,\n",
        "    train_freq=train_freq,\n",
        "    target_update_interval=target_update_interval,\n",
        "    exploration_fraction=exploration_fraction,\n",
        "    exploration_final_eps=exploration_final_eps,\n",
        "    verbose=1               # Verbose output\n",
        ")\n",
        "model.learn(total_timesteps=100000)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cby_Zfh7AA74",
        "outputId": "14bcc860-2dbd-45ff-9dda-4cf7f63a65f9"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "-----------------------------------\n",
            "| rollout/            |           |\n",
            "|    ep_len_mean      | 742       |\n",
            "|    ep_rew_mean      | -6.66e+04 |\n",
            "|    exploration_rate | 0.853     |\n",
            "| time/               |           |\n",
            "|    episodes         | 4         |\n",
            "|    fps              | 560       |\n",
            "|    time_elapsed     | 5         |\n",
            "|    total_timesteps  | 2966      |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| rollout/            |           |\n",
            "|    ep_len_mean      | 967       |\n",
            "|    ep_rew_mean      | -8.89e+04 |\n",
            "|    exploration_rate | 0.617     |\n",
            "| time/               |           |\n",
            "|    episodes         | 8         |\n",
            "|    fps              | 508       |\n",
            "|    time_elapsed     | 15        |\n",
            "|    total_timesteps  | 7734      |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| rollout/            |           |\n",
            "|    ep_len_mean      | 1.4e+03   |\n",
            "|    ep_rew_mean      | -1.32e+05 |\n",
            "|    exploration_rate | 0.169     |\n",
            "| time/               |           |\n",
            "|    episodes         | 12        |\n",
            "|    fps              | 352       |\n",
            "|    time_elapsed     | 47        |\n",
            "|    total_timesteps  | 16785     |\n",
            "| train/              |           |\n",
            "|    learning_rate    | 1e-05     |\n",
            "|    loss             | 11.4      |\n",
            "|    n_updates        | 1696      |\n",
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x7a33f171fd30>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO, A2C, DQN\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "vec_env = make_vec_env(MinesweeperEnvironment, n_envs=1)\n",
        "\n",
        "# Define hyperparameters for PPO\n",
        "learning_rate = 1e-4       # Learning rate for PPO\n",
        "n_steps = 2048             # Number of steps to run for each environment per update\n",
        "batch_size = 64            # Batch size for each update\n",
        "n_epochs = 10              # Number of times to train on each batch\n",
        "gamma = 0.99               # Discount factor\n",
        "gae_lambda = 0.95          # GAE lambda, for variance reduction in advantage estimation\n",
        "clip_range = 0.2           # Clip range for PPO, helps with stable training\n",
        "\n",
        "# Instantiate PPO with custom hyperparameters\n",
        "model = PPO(\n",
        "    \"CnnPolicy\",           # Policy type, can try \"CnnPolicy\" for image-based inputs\n",
        "    vec_env,\n",
        "    learning_rate=learning_rate,\n",
        "    n_steps=n_steps,\n",
        "    batch_size=batch_size,\n",
        "    n_epochs=n_epochs,\n",
        "    gamma=gamma,\n",
        "    gae_lambda=gae_lambda,\n",
        "    clip_range=clip_range,\n",
        "    verbose=1               # Verbose output\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=100000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "094qjCQoTEvo",
        "outputId": "7ffb92f5-7973-4293-bf68-a97f70c4e428"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 932       |\n",
            "|    ep_rew_mean     | -8.55e+04 |\n",
            "| time/              |           |\n",
            "|    fps             | 287       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 7         |\n",
            "|    total_timesteps | 2048      |\n",
            "----------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 230       |\n",
            "|    iterations           | 2         |\n",
            "|    time_elapsed         | 17        |\n",
            "|    total_timesteps      | 4096      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 42.37269  |\n",
            "|    clip_fraction        | 0.655     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.87     |\n",
            "|    explained_variance   | -7.14e-05 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 3.4e+04   |\n",
            "|    n_updates            | 10        |\n",
            "|    policy_gradient_loss | 0.146     |\n",
            "|    value_loss           | 7.23e+05  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 217       |\n",
            "|    iterations           | 3         |\n",
            "|    time_elapsed         | 28        |\n",
            "|    total_timesteps      | 6144      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.1e-10  |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.47e+04  |\n",
            "|    n_updates            | 20        |\n",
            "|    policy_gradient_loss | -2e-05    |\n",
            "|    value_loss           | 1.18e+05  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 205       |\n",
            "|    iterations           | 4         |\n",
            "|    time_elapsed         | 39        |\n",
            "|    total_timesteps      | 8192      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -5.98e-20 |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.53e+03  |\n",
            "|    n_updates            | 30        |\n",
            "|    policy_gradient_loss | 2.53e-05  |\n",
            "|    value_loss           | 5.57e+04  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 206       |\n",
            "|    iterations           | 5         |\n",
            "|    time_elapsed         | 49        |\n",
            "|    total_timesteps      | 10240     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.25e-27 |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.66e+03  |\n",
            "|    n_updates            | 40        |\n",
            "|    policy_gradient_loss | -1.71e-05 |\n",
            "|    value_loss           | 3.14e+04  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 205       |\n",
            "|    iterations           | 6         |\n",
            "|    time_elapsed         | 59        |\n",
            "|    total_timesteps      | 12288     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.68e-33 |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 239       |\n",
            "|    n_updates            | 50        |\n",
            "|    policy_gradient_loss | -3.08e-05 |\n",
            "|    value_loss           | 1.96e+04  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 202       |\n",
            "|    iterations           | 7         |\n",
            "|    time_elapsed         | 70        |\n",
            "|    total_timesteps      | 14336     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.63e-38 |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 433       |\n",
            "|    n_updates            | 60        |\n",
            "|    policy_gradient_loss | -7.09e-05 |\n",
            "|    value_loss           | 1.05e+04  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 8         |\n",
            "|    time_elapsed         | 82        |\n",
            "|    total_timesteps      | 16384     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.13e-42 |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.2e+03   |\n",
            "|    n_updates            | 70        |\n",
            "|    policy_gradient_loss | 4.22e-06  |\n",
            "|    value_loss           | 9.1e+03   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 9         |\n",
            "|    time_elapsed         | 92        |\n",
            "|    total_timesteps      | 18432     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -9.06e-46 |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.05e+03  |\n",
            "|    n_updates            | 80        |\n",
            "|    policy_gradient_loss | -4.01e-07 |\n",
            "|    value_loss           | 5.19e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 200       |\n",
            "|    iterations           | 10        |\n",
            "|    time_elapsed         | 102       |\n",
            "|    total_timesteps      | 20480     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.08e+03  |\n",
            "|    n_updates            | 90        |\n",
            "|    policy_gradient_loss | -2.79e-05 |\n",
            "|    value_loss           | 4.32e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 200       |\n",
            "|    iterations           | 11        |\n",
            "|    time_elapsed         | 112       |\n",
            "|    total_timesteps      | 22528     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 26.1      |\n",
            "|    n_updates            | 100       |\n",
            "|    policy_gradient_loss | -0.000103 |\n",
            "|    value_loss           | 2.27e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 12        |\n",
            "|    time_elapsed         | 123       |\n",
            "|    total_timesteps      | 24576     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 363       |\n",
            "|    n_updates            | 110       |\n",
            "|    policy_gradient_loss | 0.000196  |\n",
            "|    value_loss           | 1.87e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 13        |\n",
            "|    time_elapsed         | 133       |\n",
            "|    total_timesteps      | 26624     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 845       |\n",
            "|    n_updates            | 120       |\n",
            "|    policy_gradient_loss | 4.2e-06   |\n",
            "|    value_loss           | 1.47e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 14        |\n",
            "|    time_elapsed         | 144       |\n",
            "|    total_timesteps      | 28672     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.27e+03  |\n",
            "|    n_updates            | 130       |\n",
            "|    policy_gradient_loss | 0.00101   |\n",
            "|    value_loss           | 1.49e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 15        |\n",
            "|    time_elapsed         | 154       |\n",
            "|    total_timesteps      | 30720     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.79e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.62      |\n",
            "|    n_updates            | 140       |\n",
            "|    policy_gradient_loss | 0.00033   |\n",
            "|    value_loss           | 1.27e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 16        |\n",
            "|    time_elapsed         | 164       |\n",
            "|    total_timesteps      | 32768     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 28        |\n",
            "|    n_updates            | 150       |\n",
            "|    policy_gradient_loss | -4.23e-07 |\n",
            "|    value_loss           | 1.6e+03   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 17        |\n",
            "|    time_elapsed         | 175       |\n",
            "|    total_timesteps      | 34816     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 648       |\n",
            "|    n_updates            | 160       |\n",
            "|    policy_gradient_loss | 7.61e-06  |\n",
            "|    value_loss           | 1.18e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 18        |\n",
            "|    time_elapsed         | 185       |\n",
            "|    total_timesteps      | 36864     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 85.1      |\n",
            "|    n_updates            | 170       |\n",
            "|    policy_gradient_loss | 2.36e-05  |\n",
            "|    value_loss           | 964       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 19        |\n",
            "|    time_elapsed         | 195       |\n",
            "|    total_timesteps      | 38912     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 113       |\n",
            "|    n_updates            | 180       |\n",
            "|    policy_gradient_loss | -0.000431 |\n",
            "|    value_loss           | 198       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 206       |\n",
            "|    total_timesteps      | 40960     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 373       |\n",
            "|    n_updates            | 190       |\n",
            "|    policy_gradient_loss | -5.31e-05 |\n",
            "|    value_loss           | 737       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 21        |\n",
            "|    time_elapsed         | 216       |\n",
            "|    total_timesteps      | 43008     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 2.34e+03  |\n",
            "|    n_updates            | 200       |\n",
            "|    policy_gradient_loss | -2.36e-06 |\n",
            "|    value_loss           | 2.56e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 22        |\n",
            "|    time_elapsed         | 227       |\n",
            "|    total_timesteps      | 45056     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.81e+03  |\n",
            "|    n_updates            | 210       |\n",
            "|    policy_gradient_loss | 3.81e-05  |\n",
            "|    value_loss           | 2.54e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 23        |\n",
            "|    time_elapsed         | 237       |\n",
            "|    total_timesteps      | 47104     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | -2.38e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.77e+03  |\n",
            "|    n_updates            | 220       |\n",
            "|    policy_gradient_loss | 2.42e-05  |\n",
            "|    value_loss           | 2.54e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 24        |\n",
            "|    time_elapsed         | 247       |\n",
            "|    total_timesteps      | 49152     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.66e+03  |\n",
            "|    n_updates            | 230       |\n",
            "|    policy_gradient_loss | -0.000378 |\n",
            "|    value_loss           | 2.56e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 25        |\n",
            "|    time_elapsed         | 257       |\n",
            "|    total_timesteps      | 51200     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 2.38e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.57e+03  |\n",
            "|    n_updates            | 240       |\n",
            "|    policy_gradient_loss | 8.14e-05  |\n",
            "|    value_loss           | 2.59e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 26        |\n",
            "|    time_elapsed         | 268       |\n",
            "|    total_timesteps      | 53248     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.42e+03  |\n",
            "|    n_updates            | 250       |\n",
            "|    policy_gradient_loss | 3.3e-05   |\n",
            "|    value_loss           | 2.61e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 27        |\n",
            "|    time_elapsed         | 278       |\n",
            "|    total_timesteps      | 55296     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.4e+03   |\n",
            "|    n_updates            | 260       |\n",
            "|    policy_gradient_loss | -0.000763 |\n",
            "|    value_loss           | 2.64e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 28        |\n",
            "|    time_elapsed         | 288       |\n",
            "|    total_timesteps      | 57344     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 587       |\n",
            "|    n_updates            | 270       |\n",
            "|    policy_gradient_loss | 5.03e-05  |\n",
            "|    value_loss           | 2.38e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 29        |\n",
            "|    time_elapsed         | 299       |\n",
            "|    total_timesteps      | 59392     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 6.56e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.94e+03  |\n",
            "|    n_updates            | 280       |\n",
            "|    policy_gradient_loss | 0.000196  |\n",
            "|    value_loss           | 2.55e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 30        |\n",
            "|    time_elapsed         | 310       |\n",
            "|    total_timesteps      | 61440     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 4.77e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 342       |\n",
            "|    n_updates            | 290       |\n",
            "|    policy_gradient_loss | 3.72e-06  |\n",
            "|    value_loss           | 1.55e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 31        |\n",
            "|    time_elapsed         | 320       |\n",
            "|    total_timesteps      | 63488     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.07e-06  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 648       |\n",
            "|    n_updates            | 300       |\n",
            "|    policy_gradient_loss | 1.62e-05  |\n",
            "|    value_loss           | 514       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 32        |\n",
            "|    time_elapsed         | 330       |\n",
            "|    total_timesteps      | 65536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 27.6      |\n",
            "|    n_updates            | 310       |\n",
            "|    policy_gradient_loss | 6.23e-05  |\n",
            "|    value_loss           | 574       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 33        |\n",
            "|    time_elapsed         | 340       |\n",
            "|    total_timesteps      | 67584     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 80.4      |\n",
            "|    n_updates            | 320       |\n",
            "|    policy_gradient_loss | 0.000185  |\n",
            "|    value_loss           | 513       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 34        |\n",
            "|    time_elapsed         | 350       |\n",
            "|    total_timesteps      | 69632     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | -2.38e-07 |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 943       |\n",
            "|    n_updates            | 330       |\n",
            "|    policy_gradient_loss | -1.69e-05 |\n",
            "|    value_loss           | 1.17e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 35        |\n",
            "|    time_elapsed         | 361       |\n",
            "|    total_timesteps      | 71680     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 4.11e-06  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 10.7      |\n",
            "|    n_updates            | 340       |\n",
            "|    policy_gradient_loss | 5.43e-06  |\n",
            "|    value_loss           | 702       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 36        |\n",
            "|    time_elapsed         | 371       |\n",
            "|    total_timesteps      | 73728     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-06  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 32.3      |\n",
            "|    n_updates            | 350       |\n",
            "|    policy_gradient_loss | -0.000574 |\n",
            "|    value_loss           | 922       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 37        |\n",
            "|    time_elapsed         | 380       |\n",
            "|    total_timesteps      | 75776     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 6.91e-06  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 467       |\n",
            "|    n_updates            | 360       |\n",
            "|    policy_gradient_loss | -2.2e-05  |\n",
            "|    value_loss           | 3.78e+03  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 38        |\n",
            "|    time_elapsed         | 391       |\n",
            "|    total_timesteps      | 77824     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 496       |\n",
            "|    n_updates            | 370       |\n",
            "|    policy_gradient_loss | -6.9e-06  |\n",
            "|    value_loss           | 379       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 198       |\n",
            "|    iterations           | 39        |\n",
            "|    time_elapsed         | 401       |\n",
            "|    total_timesteps      | 79872     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 5.96e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.69      |\n",
            "|    n_updates            | 380       |\n",
            "|    policy_gradient_loss | -1.03e-05 |\n",
            "|    value_loss           | 551       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 411       |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 2.15e-06  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.05      |\n",
            "|    n_updates            | 390       |\n",
            "|    policy_gradient_loss | 3.03e-05  |\n",
            "|    value_loss           | 163       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 41        |\n",
            "|    time_elapsed         | 421       |\n",
            "|    total_timesteps      | 83968     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 5.96e-08  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.87      |\n",
            "|    n_updates            | 400       |\n",
            "|    policy_gradient_loss | -7.18e-06 |\n",
            "|    value_loss           | 167       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 42        |\n",
            "|    time_elapsed         | 431       |\n",
            "|    total_timesteps      | 86016     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.73e-06  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 16.8      |\n",
            "|    n_updates            | 410       |\n",
            "|    policy_gradient_loss | 0.000223  |\n",
            "|    value_loss           | 136       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 43        |\n",
            "|    time_elapsed         | 442       |\n",
            "|    total_timesteps      | 88064     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 14.9      |\n",
            "|    n_updates            | 420       |\n",
            "|    policy_gradient_loss | 0.000341  |\n",
            "|    value_loss           | 139       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 44        |\n",
            "|    time_elapsed         | 452       |\n",
            "|    total_timesteps      | 90112     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 7.75e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 13.1      |\n",
            "|    n_updates            | 430       |\n",
            "|    policy_gradient_loss | -6.96e-06 |\n",
            "|    value_loss           | 143       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 45        |\n",
            "|    time_elapsed         | 462       |\n",
            "|    total_timesteps      | 92160     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 8.34e-07  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 10        |\n",
            "|    n_updates            | 440       |\n",
            "|    policy_gradient_loss | -3.31e-06 |\n",
            "|    value_loss           | 148       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 46        |\n",
            "|    time_elapsed         | 472       |\n",
            "|    total_timesteps      | 94208     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 1.73e-05  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 7.97      |\n",
            "|    n_updates            | 450       |\n",
            "|    policy_gradient_loss | 0.000334  |\n",
            "|    value_loss           | 153       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 47        |\n",
            "|    time_elapsed         | 483       |\n",
            "|    total_timesteps      | 96256     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 4.17e-06  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 6.72      |\n",
            "|    n_updates            | 460       |\n",
            "|    policy_gradient_loss | 1.22e-06  |\n",
            "|    value_loss           | 158       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 48        |\n",
            "|    time_elapsed         | 492       |\n",
            "|    total_timesteps      | 98304     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 4.65e-06  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 5.36      |\n",
            "|    n_updates            | 470       |\n",
            "|    policy_gradient_loss | -8.1e-06  |\n",
            "|    value_loss           | 164       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | -8.55e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 199       |\n",
            "|    iterations           | 49        |\n",
            "|    time_elapsed         | 502       |\n",
            "|    total_timesteps      | 100352    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0         |\n",
            "|    explained_variance   | 3.16e-06  |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 4.2       |\n",
            "|    n_updates            | 480       |\n",
            "|    policy_gradient_loss | -0.000127 |\n",
            "|    value_loss           | 169       |\n",
            "---------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7a33f1a82ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the trained agent\n",
        "# using the vecenv\n",
        "obs = vec_env.reset()\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "    action, _ = model.predict(obs, deterministic=False)\n",
        "    # print(f\"Step {step + 1}\")\n",
        "    x = int(action[0]) // 10\n",
        "    y = int(action[0]) % 10\n",
        "    print(\"Action: \", (x, y))\n",
        "    obs, reward, done, info = vec_env.step(action)\n",
        "    print(\"reward=\", reward, \"done=\", done)\n",
        "    vec_env.render()\n",
        "    if done:\n",
        "        # Note that the VecEnv resets automatically\n",
        "        # when a done signal is encountered\n",
        "        print(\"Goal reached!\", \"reward=\", reward)\n",
        "        break"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrxjJU58AYSP",
        "outputId": "78b62168-8515-428d-e1dd-17d8f2f49979"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action:  (1, 3)\n",
            "reward= [2.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n",
            "Action:  (1, 3)\n",
            "reward= [-100.] done= [False]\n",
            "Current Board:\n",
            "* * * * * * * * * * * * 0 0 \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "* * * * * * * * * * * * * * \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rl_zoo3.train import train\n",
        "from gym.envs.registration import register\n",
        "\n",
        "register(\n",
        "    id='Minesweeper-v1',\n",
        "    entry_point='msenv:MinesweeperEnvironment',  # Update '__main__' to the module name if this is not in your main script\n",
        "    max_episode_steps=100,  # Adjust based on expected game length\n",
        ")\n",
        "\n",
        "import gym\n",
        "print([k for k in gym.envs.registry.keys() if \"Minesweeper\" in k])\n",
        "\n",
        "!python -m rl_zoo3.train --algo dqn --env Minesweeper-v1 -f logs/ -c dqn.yml\n"
      ],
      "metadata": {
        "id": "DMBhu2n2sSky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52cf6dfb-dfb8-40c3-962c-9dac4dc0f0be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:542: UserWarning: \u001b[33mWARN: Overriding environment Minesweeper-v1\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {spec.id}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Minesweeper-v1']\n",
            "2024-10-30 01:14:03.087725: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-30 01:14:03.121048: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-30 01:14:03.130907: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-30 01:14:04.389148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
            "  from jax import xla_computation as _xla_computation\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/rl_zoo3/train.py\", line 279, in <module>\n",
            "    train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/rl_zoo3/train.py\", line 175, in train\n",
            "    raise ValueError(f\"{env_id} not found in gym registry, you maybe meant {closest_match}?\")\n",
            "ValueError: Minesweeper-v1 not found in gym registry, you maybe meant 'no close match found...'?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "WH5k5ovXsZuf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}