{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMyYozhwAK84vcYLc1r7tGZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pj0620/google-colab-notebooks/blob/main/ViNG_ai2thor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grab Ai2thor data from Gdrive"
      ],
      "metadata": {
        "id": "xJiiZ8vXL1da"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m_d9ImbJfeSP",
        "outputId": "393e0b35-0707-4f6d-cbf9-72c7212292a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"1jxyQ2mA7MVJEoc_eAKPAME3go2lI16Aj\"\n",
        "output = \"ai2thor_data.npz\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output)"
      ],
      "metadata": {
        "id": "pIAUDj-5INYk",
        "outputId": "e4b2aa0a-fb56-4f0c-a7dd-cd07f34ee122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1jxyQ2mA7MVJEoc_eAKPAME3go2lI16Aj\n",
            "From (redirected): https://drive.google.com/uc?id=1jxyQ2mA7MVJEoc_eAKPAME3go2lI16Aj&confirm=t&uuid=a5aaa35a-7b5b-423f-a2d1-79130223b685\n",
            "To: /content/ai2thor_data.npz\n",
            "100%|██████████| 2.95G/2.95G [00:18<00:00, 159MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ai2thor_data.npz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load & Preprocess data"
      ],
      "metadata": {
        "id": "SaUDlMkwL8La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "ai2thor_data = np.load(\"ai2thor_data.npz\", mmap_mode=\"r\")\n",
        "images = ai2thor_data[\"images\"][:10_000, :, :, :]\n",
        "poses = ai2thor_data[\"poses\"][:10_000, :]\n",
        "\n",
        "(images, poses)"
      ],
      "metadata": {
        "id": "kIV2OacQMCoD",
        "outputId": "da800cb0-5fe9-4c90-982d-33facf9bdc36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[[216, 213, 197],\n",
              "          [216, 213, 196],\n",
              "          [215, 213, 196],\n",
              "          ...,\n",
              "          [152, 151, 136],\n",
              "          [152, 153, 138],\n",
              "          [154, 156, 140]],\n",
              " \n",
              "         [[214, 211, 194],\n",
              "          [214, 213, 196],\n",
              "          [215, 213, 196],\n",
              "          ...,\n",
              "          [151, 152, 137],\n",
              "          [152, 154, 138],\n",
              "          [155, 156, 140]],\n",
              " \n",
              "         [[210, 207, 191],\n",
              "          [214, 212, 194],\n",
              "          [215, 213, 196],\n",
              "          ...,\n",
              "          [151, 152, 136],\n",
              "          [152, 155, 138],\n",
              "          [154, 156, 140]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[246, 237, 214],\n",
              "          [241, 232, 209],\n",
              "          [240, 232, 209],\n",
              "          ...,\n",
              "          [ 63,  69,  52],\n",
              "          [ 55,  62,  45],\n",
              "          [ 50,  60,  41]],\n",
              " \n",
              "         [[246, 236, 214],\n",
              "          [244, 236, 212],\n",
              "          [247, 239, 215],\n",
              "          ...,\n",
              "          [ 66,  71,  55],\n",
              "          [ 58,  64,  48],\n",
              "          [ 53,  60,  43]],\n",
              " \n",
              "         [[247, 240, 216],\n",
              "          [245, 236, 213],\n",
              "          [247, 238, 214],\n",
              "          ...,\n",
              "          [ 70,  74,  59],\n",
              "          [ 62,  68,  52],\n",
              "          [ 55,  62,  44]]],\n",
              " \n",
              " \n",
              "        [[[114, 117, 111],\n",
              "          [114, 117, 111],\n",
              "          [113, 116, 111],\n",
              "          ...,\n",
              "          [231, 230, 211],\n",
              "          [226, 226, 206],\n",
              "          [226, 227, 206]],\n",
              " \n",
              "         [[114, 117, 111],\n",
              "          [114, 117, 112],\n",
              "          [114, 116, 111],\n",
              "          ...,\n",
              "          [228, 227, 207],\n",
              "          [226, 227, 206],\n",
              "          [224, 226, 204]],\n",
              " \n",
              "         [[114, 117, 112],\n",
              "          [114, 117, 112],\n",
              "          [113, 116, 111],\n",
              "          ...,\n",
              "          [226, 226, 206],\n",
              "          [225, 226, 206],\n",
              "          [227, 227, 207]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[109, 110, 106],\n",
              "          [110, 111, 106],\n",
              "          [109, 111, 106],\n",
              "          ...,\n",
              "          [210, 208, 187],\n",
              "          [209, 207, 187],\n",
              "          [213, 209, 190]],\n",
              " \n",
              "         [[110, 111, 106],\n",
              "          [110, 111, 106],\n",
              "          [109, 111, 106],\n",
              "          ...,\n",
              "          [213, 209, 190],\n",
              "          [209, 208, 187],\n",
              "          [213, 209, 190]],\n",
              " \n",
              "         [[109, 110, 106],\n",
              "          [109, 110, 106],\n",
              "          [109, 111, 105],\n",
              "          ...,\n",
              "          [209, 207, 187],\n",
              "          [207, 207, 187],\n",
              "          [211, 208, 190]]],\n",
              " \n",
              " \n",
              "        [[[159, 162, 151],\n",
              "          [159, 162, 152],\n",
              "          [159, 162, 151],\n",
              "          ...,\n",
              "          [255, 255, 255],\n",
              "          [255, 255, 255],\n",
              "          [130, 134, 125]],\n",
              " \n",
              "         [[159, 162, 151],\n",
              "          [159, 162, 151],\n",
              "          [159, 162, 152],\n",
              "          ...,\n",
              "          [255, 255, 255],\n",
              "          [224, 223, 209],\n",
              "          [214, 210, 189]],\n",
              " \n",
              "         [[159, 163, 152],\n",
              "          [160, 163, 153],\n",
              "          [159, 162, 152],\n",
              "          ...,\n",
              "          [211, 214, 190],\n",
              "          [213, 213, 191],\n",
              "          [214, 213, 191]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[123,  74,  48],\n",
              "          [122,  74,  48],\n",
              "          [125,  75,  49],\n",
              "          ...,\n",
              "          [164, 105,  69],\n",
              "          [166, 109,  69],\n",
              "          [171, 112,  72]],\n",
              " \n",
              "         [[125,  76,  50],\n",
              "          [125,  76,  50],\n",
              "          [126,  75,  51],\n",
              "          ...,\n",
              "          [164, 106,  69],\n",
              "          [162, 105,  67],\n",
              "          [166, 108,  70]],\n",
              " \n",
              "         [[124,  74,  48],\n",
              "          [124,  75,  51],\n",
              "          [123,  74,  50],\n",
              "          ...,\n",
              "          [164, 107,  70],\n",
              "          [162, 105,  69],\n",
              "          [163, 105,  70]]],\n",
              " \n",
              " \n",
              "        ...,\n",
              " \n",
              " \n",
              "        [[[196, 198, 184],\n",
              "          [194, 197, 182],\n",
              "          [196, 197, 184],\n",
              "          ...,\n",
              "          [162, 162, 148],\n",
              "          [162, 163, 148],\n",
              "          [162, 163, 148]],\n",
              " \n",
              "         [[196, 197, 183],\n",
              "          [194, 197, 182],\n",
              "          [196, 198, 184],\n",
              "          ...,\n",
              "          [161, 161, 146],\n",
              "          [161, 162, 147],\n",
              "          [161, 162, 147]],\n",
              " \n",
              "         [[196, 197, 184],\n",
              "          [194, 196, 181],\n",
              "          [196, 197, 183],\n",
              "          ...,\n",
              "          [160, 161, 146],\n",
              "          [159, 161, 146],\n",
              "          [159, 161, 145]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[216, 216, 199],\n",
              "          [216, 216, 199],\n",
              "          [218, 216, 200],\n",
              "          ...,\n",
              "          [122,  84,  55],\n",
              "          [122,  83,  54],\n",
              "          [122,  83,  55]],\n",
              " \n",
              "         [[215, 215, 197],\n",
              "          [213, 215, 196],\n",
              "          [214, 214, 197],\n",
              "          ...,\n",
              "          [131,  89,  57],\n",
              "          [127,  86,  56],\n",
              "          [123,  84,  55]],\n",
              " \n",
              "         [[213, 214, 195],\n",
              "          [215, 215, 197],\n",
              "          [211, 213, 194],\n",
              "          ...,\n",
              "          [122,  82,  55],\n",
              "          [125,  84,  56],\n",
              "          [127,  86,  56]]],\n",
              " \n",
              " \n",
              "        [[[132, 137, 128],\n",
              "          [124, 119,  96],\n",
              "          [124, 120,  96],\n",
              "          ...,\n",
              "          [182, 183, 163],\n",
              "          [183, 184, 163],\n",
              "          [184, 185, 164]],\n",
              " \n",
              "         [[132, 137, 129],\n",
              "          [132, 137, 129],\n",
              "          [133, 137, 129],\n",
              "          ...,\n",
              "          [183, 184, 163],\n",
              "          [183, 183, 163],\n",
              "          [184, 184, 164]],\n",
              " \n",
              "         [[133, 137, 129],\n",
              "          [132, 137, 129],\n",
              "          [132, 137, 129],\n",
              "          ...,\n",
              "          [182, 182, 163],\n",
              "          [182, 182, 163],\n",
              "          [183, 182, 163]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[135, 137, 127],\n",
              "          [136, 137, 127],\n",
              "          [136, 137, 126],\n",
              "          ...,\n",
              "          [ 12,  12,  11],\n",
              "          [ 12,  11,  11],\n",
              "          [ 12,  11,  11]],\n",
              " \n",
              "         [[136, 137, 127],\n",
              "          [136, 137, 127],\n",
              "          [135, 137, 127],\n",
              "          ...,\n",
              "          [ 13,  12,  11],\n",
              "          [ 12,  12,  11],\n",
              "          [ 12,  12,  11]],\n",
              " \n",
              "         [[136, 137, 126],\n",
              "          [136, 137, 126],\n",
              "          [136, 137, 126],\n",
              "          ...,\n",
              "          [ 13,  12,  11],\n",
              "          [ 13,  12,  11],\n",
              "          [ 12,  12,  11]]],\n",
              " \n",
              " \n",
              "        [[[214, 213, 190],\n",
              "          [214, 214, 190],\n",
              "          [215, 215, 191],\n",
              "          ...,\n",
              "          [135, 136, 124],\n",
              "          [134, 135, 123],\n",
              "          [133, 135, 122]],\n",
              " \n",
              "         [[212, 212, 188],\n",
              "          [213, 213, 189],\n",
              "          [214, 214, 190],\n",
              "          ...,\n",
              "          [134, 135, 123],\n",
              "          [133, 134, 122],\n",
              "          [132, 134, 121]],\n",
              " \n",
              "         [[211, 211, 187],\n",
              "          [212, 213, 188],\n",
              "          [213, 214, 189],\n",
              "          ...,\n",
              "          [133, 134, 122],\n",
              "          [133, 133, 121],\n",
              "          [159, 155, 125]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[187, 119,  72],\n",
              "          [190, 120,  73],\n",
              "          [191, 122,  74],\n",
              "          ...,\n",
              "          [173, 175, 161],\n",
              "          [173, 175, 160],\n",
              "          [174, 175, 161]],\n",
              " \n",
              "         [[191, 123,  76],\n",
              "          [193, 124,  76],\n",
              "          [193, 124,  76],\n",
              "          ...,\n",
              "          [173, 175, 161],\n",
              "          [172, 175, 159],\n",
              "          [173, 175, 161]],\n",
              " \n",
              "         [[190, 121,  76],\n",
              "          [193, 123,  75],\n",
              "          [191, 121,  76],\n",
              "          ...,\n",
              "          [172, 175, 161],\n",
              "          [172, 176, 159],\n",
              "          [173, 175, 160]]]], dtype=uint8),\n",
              " array([[ 2.50000000e-01,  9.00999248e-01,  1.25000000e+00,\n",
              "          1.22832786e+02],\n",
              "        [ 2.50000000e-01,  9.00999248e-01,  2.25000000e+00,\n",
              "          8.33624670e+01],\n",
              "        [-3.50000000e+00,  9.00999248e-01,  1.75000000e+00,\n",
              "          5.13303747e+01],\n",
              "        ...,\n",
              "        [-3.50000000e+00,  9.00999248e-01,  5.00000000e-01,\n",
              "          3.38191194e+02],\n",
              "        [-5.00000000e-01,  9.00999248e-01,  2.75000000e+00,\n",
              "          1.47886457e+02],\n",
              "        [-3.00000000e+00,  9.00999248e-01,  2.25000000e+00,\n",
              "          1.76195914e+02]]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing"
      ],
      "metadata": {
        "id": "a-MTZ9hJMtLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poses_no_height = np.delete(poses, 1, 1)\n",
        "poses_no_height\n",
        "\n",
        "mins = np.min(poses_no_height, axis=0)\n",
        "maxes = np.max(poses_no_height, axis=0)\n",
        "\n",
        "poses_normalized = (poses_no_height - mins) / (maxes - mins)\n",
        "poses_normalized"
      ],
      "metadata": {
        "id": "7PDsStjKM8E5",
        "outputId": "05cb3578-5de0-44e0-b1c9-033b4caf7c80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.88888889, 0.7       , 0.3411191 ],\n",
              "       [0.88888889, 0.9       , 0.23146405],\n",
              "       [0.05555556, 0.8       , 0.14247362],\n",
              "       ...,\n",
              "       [0.05555556, 0.55      , 0.93942025],\n",
              "       [0.72222222, 1.        , 0.41072233],\n",
              "       [0.16666667, 0.9       , 0.48937067]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_normalized = images / 255\n",
        "del images\n",
        "images_normalized"
      ],
      "metadata": {
        "id": "-dI1RPIxN4M3",
        "outputId": "f2977c8c-baa0-458d-8f04-9507ac01de4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.84705882, 0.83529412, 0.77254902],\n",
              "         [0.84705882, 0.83529412, 0.76862745],\n",
              "         [0.84313725, 0.83529412, 0.76862745],\n",
              "         ...,\n",
              "         [0.59607843, 0.59215686, 0.53333333],\n",
              "         [0.59607843, 0.6       , 0.54117647],\n",
              "         [0.60392157, 0.61176471, 0.54901961]],\n",
              "\n",
              "        [[0.83921569, 0.82745098, 0.76078431],\n",
              "         [0.83921569, 0.83529412, 0.76862745],\n",
              "         [0.84313725, 0.83529412, 0.76862745],\n",
              "         ...,\n",
              "         [0.59215686, 0.59607843, 0.5372549 ],\n",
              "         [0.59607843, 0.60392157, 0.54117647],\n",
              "         [0.60784314, 0.61176471, 0.54901961]],\n",
              "\n",
              "        [[0.82352941, 0.81176471, 0.74901961],\n",
              "         [0.83921569, 0.83137255, 0.76078431],\n",
              "         [0.84313725, 0.83529412, 0.76862745],\n",
              "         ...,\n",
              "         [0.59215686, 0.59607843, 0.53333333],\n",
              "         [0.59607843, 0.60784314, 0.54117647],\n",
              "         [0.60392157, 0.61176471, 0.54901961]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.96470588, 0.92941176, 0.83921569],\n",
              "         [0.94509804, 0.90980392, 0.81960784],\n",
              "         [0.94117647, 0.90980392, 0.81960784],\n",
              "         ...,\n",
              "         [0.24705882, 0.27058824, 0.20392157],\n",
              "         [0.21568627, 0.24313725, 0.17647059],\n",
              "         [0.19607843, 0.23529412, 0.16078431]],\n",
              "\n",
              "        [[0.96470588, 0.9254902 , 0.83921569],\n",
              "         [0.95686275, 0.9254902 , 0.83137255],\n",
              "         [0.96862745, 0.9372549 , 0.84313725],\n",
              "         ...,\n",
              "         [0.25882353, 0.27843137, 0.21568627],\n",
              "         [0.22745098, 0.25098039, 0.18823529],\n",
              "         [0.20784314, 0.23529412, 0.16862745]],\n",
              "\n",
              "        [[0.96862745, 0.94117647, 0.84705882],\n",
              "         [0.96078431, 0.9254902 , 0.83529412],\n",
              "         [0.96862745, 0.93333333, 0.83921569],\n",
              "         ...,\n",
              "         [0.2745098 , 0.29019608, 0.23137255],\n",
              "         [0.24313725, 0.26666667, 0.20392157],\n",
              "         [0.21568627, 0.24313725, 0.17254902]]],\n",
              "\n",
              "\n",
              "       [[[0.44705882, 0.45882353, 0.43529412],\n",
              "         [0.44705882, 0.45882353, 0.43529412],\n",
              "         [0.44313725, 0.45490196, 0.43529412],\n",
              "         ...,\n",
              "         [0.90588235, 0.90196078, 0.82745098],\n",
              "         [0.88627451, 0.88627451, 0.80784314],\n",
              "         [0.88627451, 0.89019608, 0.80784314]],\n",
              "\n",
              "        [[0.44705882, 0.45882353, 0.43529412],\n",
              "         [0.44705882, 0.45882353, 0.43921569],\n",
              "         [0.44705882, 0.45490196, 0.43529412],\n",
              "         ...,\n",
              "         [0.89411765, 0.89019608, 0.81176471],\n",
              "         [0.88627451, 0.89019608, 0.80784314],\n",
              "         [0.87843137, 0.88627451, 0.8       ]],\n",
              "\n",
              "        [[0.44705882, 0.45882353, 0.43921569],\n",
              "         [0.44705882, 0.45882353, 0.43921569],\n",
              "         [0.44313725, 0.45490196, 0.43529412],\n",
              "         ...,\n",
              "         [0.88627451, 0.88627451, 0.80784314],\n",
              "         [0.88235294, 0.88627451, 0.80784314],\n",
              "         [0.89019608, 0.89019608, 0.81176471]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.42745098, 0.43137255, 0.41568627],\n",
              "         [0.43137255, 0.43529412, 0.41568627],\n",
              "         [0.42745098, 0.43529412, 0.41568627],\n",
              "         ...,\n",
              "         [0.82352941, 0.81568627, 0.73333333],\n",
              "         [0.81960784, 0.81176471, 0.73333333],\n",
              "         [0.83529412, 0.81960784, 0.74509804]],\n",
              "\n",
              "        [[0.43137255, 0.43529412, 0.41568627],\n",
              "         [0.43137255, 0.43529412, 0.41568627],\n",
              "         [0.42745098, 0.43529412, 0.41568627],\n",
              "         ...,\n",
              "         [0.83529412, 0.81960784, 0.74509804],\n",
              "         [0.81960784, 0.81568627, 0.73333333],\n",
              "         [0.83529412, 0.81960784, 0.74509804]],\n",
              "\n",
              "        [[0.42745098, 0.43137255, 0.41568627],\n",
              "         [0.42745098, 0.43137255, 0.41568627],\n",
              "         [0.42745098, 0.43529412, 0.41176471],\n",
              "         ...,\n",
              "         [0.81960784, 0.81176471, 0.73333333],\n",
              "         [0.81176471, 0.81176471, 0.73333333],\n",
              "         [0.82745098, 0.81568627, 0.74509804]]],\n",
              "\n",
              "\n",
              "       [[[0.62352941, 0.63529412, 0.59215686],\n",
              "         [0.62352941, 0.63529412, 0.59607843],\n",
              "         [0.62352941, 0.63529412, 0.59215686],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [0.50980392, 0.5254902 , 0.49019608]],\n",
              "\n",
              "        [[0.62352941, 0.63529412, 0.59215686],\n",
              "         [0.62352941, 0.63529412, 0.59215686],\n",
              "         [0.62352941, 0.63529412, 0.59607843],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [0.87843137, 0.8745098 , 0.81960784],\n",
              "         [0.83921569, 0.82352941, 0.74117647]],\n",
              "\n",
              "        [[0.62352941, 0.63921569, 0.59607843],\n",
              "         [0.62745098, 0.63921569, 0.6       ],\n",
              "         [0.62352941, 0.63529412, 0.59607843],\n",
              "         ...,\n",
              "         [0.82745098, 0.83921569, 0.74509804],\n",
              "         [0.83529412, 0.83529412, 0.74901961],\n",
              "         [0.83921569, 0.83529412, 0.74901961]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.48235294, 0.29019608, 0.18823529],\n",
              "         [0.47843137, 0.29019608, 0.18823529],\n",
              "         [0.49019608, 0.29411765, 0.19215686],\n",
              "         ...,\n",
              "         [0.64313725, 0.41176471, 0.27058824],\n",
              "         [0.65098039, 0.42745098, 0.27058824],\n",
              "         [0.67058824, 0.43921569, 0.28235294]],\n",
              "\n",
              "        [[0.49019608, 0.29803922, 0.19607843],\n",
              "         [0.49019608, 0.29803922, 0.19607843],\n",
              "         [0.49411765, 0.29411765, 0.2       ],\n",
              "         ...,\n",
              "         [0.64313725, 0.41568627, 0.27058824],\n",
              "         [0.63529412, 0.41176471, 0.2627451 ],\n",
              "         [0.65098039, 0.42352941, 0.2745098 ]],\n",
              "\n",
              "        [[0.48627451, 0.29019608, 0.18823529],\n",
              "         [0.48627451, 0.29411765, 0.2       ],\n",
              "         [0.48235294, 0.29019608, 0.19607843],\n",
              "         ...,\n",
              "         [0.64313725, 0.41960784, 0.2745098 ],\n",
              "         [0.63529412, 0.41176471, 0.27058824],\n",
              "         [0.63921569, 0.41176471, 0.2745098 ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.76862745, 0.77647059, 0.72156863],\n",
              "         [0.76078431, 0.77254902, 0.71372549],\n",
              "         [0.76862745, 0.77254902, 0.72156863],\n",
              "         ...,\n",
              "         [0.63529412, 0.63529412, 0.58039216],\n",
              "         [0.63529412, 0.63921569, 0.58039216],\n",
              "         [0.63529412, 0.63921569, 0.58039216]],\n",
              "\n",
              "        [[0.76862745, 0.77254902, 0.71764706],\n",
              "         [0.76078431, 0.77254902, 0.71372549],\n",
              "         [0.76862745, 0.77647059, 0.72156863],\n",
              "         ...,\n",
              "         [0.63137255, 0.63137255, 0.57254902],\n",
              "         [0.63137255, 0.63529412, 0.57647059],\n",
              "         [0.63137255, 0.63529412, 0.57647059]],\n",
              "\n",
              "        [[0.76862745, 0.77254902, 0.72156863],\n",
              "         [0.76078431, 0.76862745, 0.70980392],\n",
              "         [0.76862745, 0.77254902, 0.71764706],\n",
              "         ...,\n",
              "         [0.62745098, 0.63137255, 0.57254902],\n",
              "         [0.62352941, 0.63137255, 0.57254902],\n",
              "         [0.62352941, 0.63137255, 0.56862745]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.84705882, 0.84705882, 0.78039216],\n",
              "         [0.84705882, 0.84705882, 0.78039216],\n",
              "         [0.85490196, 0.84705882, 0.78431373],\n",
              "         ...,\n",
              "         [0.47843137, 0.32941176, 0.21568627],\n",
              "         [0.47843137, 0.3254902 , 0.21176471],\n",
              "         [0.47843137, 0.3254902 , 0.21568627]],\n",
              "\n",
              "        [[0.84313725, 0.84313725, 0.77254902],\n",
              "         [0.83529412, 0.84313725, 0.76862745],\n",
              "         [0.83921569, 0.83921569, 0.77254902],\n",
              "         ...,\n",
              "         [0.51372549, 0.34901961, 0.22352941],\n",
              "         [0.49803922, 0.3372549 , 0.21960784],\n",
              "         [0.48235294, 0.32941176, 0.21568627]],\n",
              "\n",
              "        [[0.83529412, 0.83921569, 0.76470588],\n",
              "         [0.84313725, 0.84313725, 0.77254902],\n",
              "         [0.82745098, 0.83529412, 0.76078431],\n",
              "         ...,\n",
              "         [0.47843137, 0.32156863, 0.21568627],\n",
              "         [0.49019608, 0.32941176, 0.21960784],\n",
              "         [0.49803922, 0.3372549 , 0.21960784]]],\n",
              "\n",
              "\n",
              "       [[[0.51764706, 0.5372549 , 0.50196078],\n",
              "         [0.48627451, 0.46666667, 0.37647059],\n",
              "         [0.48627451, 0.47058824, 0.37647059],\n",
              "         ...,\n",
              "         [0.71372549, 0.71764706, 0.63921569],\n",
              "         [0.71764706, 0.72156863, 0.63921569],\n",
              "         [0.72156863, 0.7254902 , 0.64313725]],\n",
              "\n",
              "        [[0.51764706, 0.5372549 , 0.50588235],\n",
              "         [0.51764706, 0.5372549 , 0.50588235],\n",
              "         [0.52156863, 0.5372549 , 0.50588235],\n",
              "         ...,\n",
              "         [0.71764706, 0.72156863, 0.63921569],\n",
              "         [0.71764706, 0.71764706, 0.63921569],\n",
              "         [0.72156863, 0.72156863, 0.64313725]],\n",
              "\n",
              "        [[0.52156863, 0.5372549 , 0.50588235],\n",
              "         [0.51764706, 0.5372549 , 0.50588235],\n",
              "         [0.51764706, 0.5372549 , 0.50588235],\n",
              "         ...,\n",
              "         [0.71372549, 0.71372549, 0.63921569],\n",
              "         [0.71372549, 0.71372549, 0.63921569],\n",
              "         [0.71764706, 0.71372549, 0.63921569]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.52941176, 0.5372549 , 0.49803922],\n",
              "         [0.53333333, 0.5372549 , 0.49803922],\n",
              "         [0.53333333, 0.5372549 , 0.49411765],\n",
              "         ...,\n",
              "         [0.04705882, 0.04705882, 0.04313725],\n",
              "         [0.04705882, 0.04313725, 0.04313725],\n",
              "         [0.04705882, 0.04313725, 0.04313725]],\n",
              "\n",
              "        [[0.53333333, 0.5372549 , 0.49803922],\n",
              "         [0.53333333, 0.5372549 , 0.49803922],\n",
              "         [0.52941176, 0.5372549 , 0.49803922],\n",
              "         ...,\n",
              "         [0.05098039, 0.04705882, 0.04313725],\n",
              "         [0.04705882, 0.04705882, 0.04313725],\n",
              "         [0.04705882, 0.04705882, 0.04313725]],\n",
              "\n",
              "        [[0.53333333, 0.5372549 , 0.49411765],\n",
              "         [0.53333333, 0.5372549 , 0.49411765],\n",
              "         [0.53333333, 0.5372549 , 0.49411765],\n",
              "         ...,\n",
              "         [0.05098039, 0.04705882, 0.04313725],\n",
              "         [0.05098039, 0.04705882, 0.04313725],\n",
              "         [0.04705882, 0.04705882, 0.04313725]]],\n",
              "\n",
              "\n",
              "       [[[0.83921569, 0.83529412, 0.74509804],\n",
              "         [0.83921569, 0.83921569, 0.74509804],\n",
              "         [0.84313725, 0.84313725, 0.74901961],\n",
              "         ...,\n",
              "         [0.52941176, 0.53333333, 0.48627451],\n",
              "         [0.5254902 , 0.52941176, 0.48235294],\n",
              "         [0.52156863, 0.52941176, 0.47843137]],\n",
              "\n",
              "        [[0.83137255, 0.83137255, 0.7372549 ],\n",
              "         [0.83529412, 0.83529412, 0.74117647],\n",
              "         [0.83921569, 0.83921569, 0.74509804],\n",
              "         ...,\n",
              "         [0.5254902 , 0.52941176, 0.48235294],\n",
              "         [0.52156863, 0.5254902 , 0.47843137],\n",
              "         [0.51764706, 0.5254902 , 0.4745098 ]],\n",
              "\n",
              "        [[0.82745098, 0.82745098, 0.73333333],\n",
              "         [0.83137255, 0.83529412, 0.7372549 ],\n",
              "         [0.83529412, 0.83921569, 0.74117647],\n",
              "         ...,\n",
              "         [0.52156863, 0.5254902 , 0.47843137],\n",
              "         [0.52156863, 0.52156863, 0.4745098 ],\n",
              "         [0.62352941, 0.60784314, 0.49019608]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.73333333, 0.46666667, 0.28235294],\n",
              "         [0.74509804, 0.47058824, 0.28627451],\n",
              "         [0.74901961, 0.47843137, 0.29019608],\n",
              "         ...,\n",
              "         [0.67843137, 0.68627451, 0.63137255],\n",
              "         [0.67843137, 0.68627451, 0.62745098],\n",
              "         [0.68235294, 0.68627451, 0.63137255]],\n",
              "\n",
              "        [[0.74901961, 0.48235294, 0.29803922],\n",
              "         [0.75686275, 0.48627451, 0.29803922],\n",
              "         [0.75686275, 0.48627451, 0.29803922],\n",
              "         ...,\n",
              "         [0.67843137, 0.68627451, 0.63137255],\n",
              "         [0.6745098 , 0.68627451, 0.62352941],\n",
              "         [0.67843137, 0.68627451, 0.63137255]],\n",
              "\n",
              "        [[0.74509804, 0.4745098 , 0.29803922],\n",
              "         [0.75686275, 0.48235294, 0.29411765],\n",
              "         [0.74901961, 0.4745098 , 0.29803922],\n",
              "         ...,\n",
              "         [0.6745098 , 0.68627451, 0.63137255],\n",
              "         [0.6745098 , 0.69019608, 0.62352941],\n",
              "         [0.67843137, 0.68627451, 0.62745098]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test train split"
      ],
      "metadata": {
        "id": "o7tDgRZ2PCKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "num_samples = images_normalized.shape[0]\n",
        "image_size = (3, 128, 128)  # Channels x Height x Width\n",
        "pose_size = 3  # Pose vector size x, z, angle\n",
        "\n",
        "\n",
        "images_tensor = torch.tensor(images_normalized, dtype=torch.float32)\n",
        "poses_tensor = torch.tensor(poses_normalized, dtype=torch.float32)\n",
        "\n",
        "# Step 2: Create a dataset and split into train and test\n",
        "dataset = TensorDataset(images_tensor, poses_tensor)\n",
        "\n",
        "# Define split sizes\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# Perform train-test split\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Step 3: Define the CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)  # Input channels = 3 (RGB)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(32 * 32 * 32, 128)  # Adjusted for output of conv2/pool layers\n",
        "        self.fc2 = nn.Linear(128, 3)  # Output size = pose vector size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Step 4: Define loss function and optimizer\n",
        "criterion = nn.MSELoss()  # Loss for regression\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 5: Train the model\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images_batch, poses_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        images_batch = images_batch.permute(0, 3, 1, 2)\n",
        "        outputs = model(images_batch)\n",
        "        loss = criterion(outputs, poses_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "ApAFMUIpP8i-",
        "outputId": "555d916f-ff4e-4c34-db82-0fd8891f6362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.1376\n",
            "Epoch 2/10, Loss: 0.0484\n",
            "Epoch 3/10, Loss: 0.0293\n",
            "Epoch 4/10, Loss: 0.0216\n",
            "Epoch 5/10, Loss: 0.0170\n",
            "Epoch 6/10, Loss: 0.0146\n",
            "Epoch 7/10, Loss: 0.0124\n",
            "Epoch 8/10, Loss: 0.0111\n",
            "Epoch 9/10, Loss: 0.0097\n",
            "Epoch 10/10, Loss: 0.0089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate with test data"
      ],
      "metadata": {
        "id": "PvaVvR2XXgQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate the model\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "\n",
        "# Disable gradient computation for evaluation\n",
        "with torch.no_grad():\n",
        "    for images_batch, poses_batch in test_loader:\n",
        "        # Adjust input shape to (N, C, H, W)\n",
        "        images_batch = images_batch.permute(0, 3, 1, 2)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images_batch)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, poses_batch)\n",
        "\n",
        "        # Accumulate loss\n",
        "        test_loss += loss.item()\n",
        "\n",
        "# Print test loss\n",
        "print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")"
      ],
      "metadata": {
        "id": "ipOvOYA-XfvN",
        "outputId": "f94fc276-9289-409e-a58b-ff704913cd0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0142\n"
          ]
        }
      ]
    }
  ]
}